---
title: "Snippets"
author: "Anne"
date: "8-1-2020"
output: html_document
highlight: NULL
---
### tryCatch
```{r setup, include=FALSE}
install.packages("tidyverse")
knitr::opts_chunk$set(echo = TRUE)
inputs = list(1, 2, 4, -5, 'oops', 0, 10)
for(input in inputs) {
    tryCatch(print(paste("log of", input, "=", log(input))),
             warning = function(w) 
               {print(paste("negative argument", input)); 
                                      log(-input)},
             error = function(e) 
               {print(paste("non-numeric argument", input));
                               NaN})
}

(r <- seq_along(1:3))
  
library(tidyverse)

```
<div style="margin-bottom:40px;">
</div>

# R for Data Science 

## ggplot 

```{r include = T}
# What does stroke do
ggplot(mtcars, aes(wt, mpg)) +
  geom_point(shape = 21, colour = "black", fill = "white", size = 2, stroke = 4)

# 6. Map aesthetic to sth other than a variable name 
ggplot(mpg, aes(x = displ, y = hwy, colour = displ < 6)) +
  geom_point()

# The variables color and clarity are ordered categorical variables. The chapter suggests visualizing a categorical and continuous variable using *frequency polygons* or *boxplots*.

diamonds %>%
  mutate(color = fct_rev(color)) %>% # I will reverse the order of the color levels so they will be in increasing order of quality on the x-axis. 
  ggplot(aes(x = color, y = price)) +
  geom_boxplot()

ggplot(data = diamonds) +
  geom_boxplot(mapping = aes(x = clarity, y = price))


#For both clarity and color, there is a much larger amount of variation within each category than between categories. Carat is clearly the single best predictor of diamond prices.
```


### boxplot


```{r include = T}
#Now that we have established that carat appears to be the best predictor of price, what is the relationship between it and cut? Since this is an example of a continuous (carat) and categorical (cut) variable, it can be visualized with a box plot.

ggplot(diamonds, aes(x = cut, y = carat)) +
  geom_boxplot()

#There is a lot of variability in the distribution of carat sizes within each cut category. There is a slight negative relationship between carat and cut. Noticeably, the largest carat diamonds have a cut of “Fair” (the lowest).
```

### letter-value plot:

```{r include = T}
library(lvplot)
ggplot(diamonds, aes(x = cut, y = price)) +
  geom_lv()

#Larger datasets afford more precise estimates of *tail behavior*, but boxplots do not take advantage of this precision, instead presenting large numbers of extreme, though not unexpected, observations. Letter-value plots address this problem by including more detailed information about the tails using “letter values,” an order statistic defined by Tukey. Boxplots display the first two letter values (the median and quartiles); letter-value plots display further letter values so far as they are reliable estimates of their corresponding quantiles.

```

### freq plot

```{r include = T}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```

### Histogram

```{r include = T}
ggplot(data = diamonds, mapping = aes(x = price)) +
  geom_histogram() +
  facet_wrap(~cut, ncol = 1, scales = "free_y")
```

### Violin plot 

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_violin() +
  coord_flip()
```

## ggplot exercises 
* How could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?
* To clearly show the distribution of cut within color, calculate a new variable prop which is the proportion of each cut within a color. This is done using a grouped mutate.

```{r}
library(viridis)
diamonds %>%
  count(color, cut) %>%
  group_by(color) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(mapping = aes(x = color, y = cut)) +
  geom_tile(mapping = aes(fill = prop)) +
  scale_fill_viridis(limits = c(0, 1)) # add limit = c(0, 1) to put the color scale between (0, 1). These are the logical boundaries of proportions. 
```


* Use *geom_tile()* together with dplyr to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?

```{r}
flights %>%
  group_by(month, dest) %>%
  summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(x = factor(month), y = dest, fill = dep_delay)) +
  geom_tile() +
  labs(x = "Month", y = "Destination", fill = "Departure Delay")


# better:

flights %>%
  group_by(month,dest) %>%
  summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  group_by(dest) %>%
  filter(n() == 12) %>% ##delete missing data (not flying in every month)
  ungroup() %>%
  mutate(dest = reorder(dest, dep_delay)) %>%
  ggplot(aes(x = factor(month), y = dest, fill = dep_delay)) +
  geom_tile() +
  scale_fill_viridis() +
  labs(x = "Month", y = "Destination", fill = "Departure Delay")

?reorder

```

#### Scatterplots
* use *alpha aesthetics* to add transparency 

```{r}
library(ggplot2)
ggplot(data = diamonds) + 
  geom_point(
    mapping = aes(x = carat, y = price),
    alpha = 1/100
  )

# or, probably even better: use *geom_bin2d* or *geom_hex* plots:

ggplot(data = diamonds) + 
  geom_bin2d(mapping = aes(x = carat, y = price))

library(hexbin)
ggplot(data = diamonds) + 
  geom_hex(mapping = aes(x = carat, y = price))


# or treat one cont variable as a categorical variable and use *boxplot*:

ggplot(data = diamonds, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))


# in order to see hdifference in number of observations, use: *varwidth = TRUE* or use *cut_number* to display the same amount of points in each bin!

ggplot(data = diamonds, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group= cut_number(carat, 20)))
```


#### filter

* choose certain variables only

```{r}
library(nycflights13)
data("flights")
filter(flights, month >= 7, month <= 9)

# %in%
filter(flights, month %in% 7:9)

# between
filter(flights, between(month, 7, 9))

filter(flights, dest == "IAH" | dest == "HOU")

filter(flights, is.na(dep_time))
```

#### arrange 

```{r}
#sorting in ascending order: 
arrange(flights, dep_delay)

# put NA first: 
arrange(flights, desc(is.na(dep_time)), dep_time)
```


#### mutate

```{r}
# calculate new variables and add them

fastest_flights <- mutate(flights, mph = distance / air_time * 60)
# transmute() to keep only new variables 

fastest_flights <- transmute(flights,
    dep_time_min = (dep_time %/% 100 * 60 + dep_time %% 100) %% 1440,
    sched_dep_time_min = (sched_dep_time %/% 100 * 60 +
      sched_dep_time %% 100) %% 1440,
    dep_delay_diff = dep_delay - dep_time_min + sched_dep_time_min
  )

```

#### select

```{r}
# select by variable name: 
fastest_flights <- select(
  fastest_flights, mph, distance, air_time,
  flight, origin, dest, year, month, day
)
# select by column names as strings: 
select(flights, "dep_time", "dep_delay", "arr_time", "arr_delay")

#select by column numbers:
select(flights, 4, 6, 7, 9)

#Specify the names of the variables with character vector and one_of(): 
variables <- c("dep_time", "dep_delay", "arr_time", "arr_delay")
select(flights, one_of(variables))

# starts_with: 
select(flights, starts_with("dep_"), starts_with("arr_"))

# matches: 
select(flights, matches("^(dep|arr)_(time|delay)$"))

# contains: 
select(flights, contains("_time"), contains("arr_"))

#case-sensitive selection: ignore.case = FALSE
```

#### ranking

```{r}
# row_number(): equivalent to row index 

# Using row_number() with mutate() will create a column of consecutive numbers. The row_number() function is useful for creating an identification number (an ID variable). It is also useful for labeling each observation by a grouping variable.

flights %>% mutate(session = row_number())

flights %>% group_by(hour, dest) %>% mutate(session = row_number()) %>% arrange(., dest)

#  min_rank(): assigns a rank equal to the number of values less than that tied value plus one
# The min_rank() function is a function that returns the same values as rank when the ties_method is set to "min"
X <- c(24,22,22,23,21)
min_rank(X)
#> [1] 5 2 2 4 1
rank(X, ties.method = "min")
#> [1] 5 2 2 4 1
rank(X, ties.method = "max")
#> [1] 5 3 3 4 1

# dense_rank(): assigns a rank equal to the number of distinct values less than that tied value plus one
dense_rank(X)
```

#### group_by

* creates grouping variable
* to use variable normally afterward, call ungroup()

```{r}
by_cyl <- mtcars %>% group_by(cyl)
# grouping doesn't change how the data looks (apart from listing
# how it's grouped):
by_cyl

# It changes how it acts with the other dplyr verbs:
by_cyl %>% summarise(
  disp = mean(disp),
  hp = mean(hp)
)

by_cyl %>% filter(disp == max(disp))

# Each call to summarise() removes a layer of grouping
by_vs_am <- mtcars %>% group_by(vs, am)
by_vs <- by_vs_am %>% summarise(n = n())
by_vs
by_vs %>% summarise(n = sum(n))


# To removing grouping, use ungroup
by_vs %>%
  ungroup() %>%
  summarise(n = sum(n))

# You can group by expressions: this is just short-hand for
# a mutate/rename followed by a simple group_by
mtcars %>% group_by(vsam = vs + am)

# By default, group_by overrides existing grouping
by_cyl %>%
  group_by(vs, am) %>%
  group_vars()


not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))


delays <- not_cancelled %>% 
  group_by(month, flight, minute) %>% 
  summarize(
    delay = mean(arr_delay), delay_sd = sd(arr_delay),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10)


delays %>% 
  filter(n > 2) %>% 
  ggplot(mapping = aes(x = n, y = delay)) +
  geom_point(alpha = 1/4)


# progressively rolling up summaries*
daily <- group_by(flights, year, month, day)
(per_day <- dplyr::summarize(daily, count = n()))
(per_month <- dplyr::summarize(per_day, count = n()))
(per_month <- dplyr::summarize(per_day, count = n()))
(per_month <- dplyr::summarize(per_month, count = n()))



# Grouped Mutates (and filters)
# Grouping is most useful in conjunction with summarise(), but you can also use it with mutate() and 
# For example: find the worst members in a group

flights %>%
  group_by(year, month, day) %>%
  select(year, month, day, arr_delay, carrier) %>%
  filter(rank(desc(arr_delay)) < 10 )


# find all groups bigger than a threshold 
(popular_dest <- flights %>%
    group_by(dest) %>%
    filter(n() > 365) %>%
    summarize(mean = mean(arr_delay, na.rm =T))) 
head(arrange(popular_dest, desc(mean)))
      
(unpopular_dest <- flights %>%
group_by(dest) %>%
    filter(n() < 365) %>%
    summarize(mean = mean(arr_delay, na.rm =T))) 
head(arrange(unpopular_dest, desc(mean)))

## How do mutate and filtering functions change when combined with grouping?
# Summary functions (mean()), offset functions (lead(), lag()), ranking functions (min_rank(), row_number()), operate within each group when used with group_by() in mutate() or filter(). Arithmetic operators (+, -), logical operators (<, ==), modular arithmetic operators (%%, %/%), logarithmic functions (log) are not affected by group_by

## Summary functions like mean(), median(), sum(), std() and others covered in the section "Useful Summary Functions" calculate their values within each group when used with mutate() or filter() and group_by().

## different means, depending on whether overall mean is called or group mean (by group_by)
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(x_mean = mean(x)) %>%
  group_by(group) %>%
  mutate(x_mean_2 = mean(x)))


# Arithmetic operators are not affected by group_by()
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(y = x + 2) %>%
  group_by(group) %>%
  mutate(z = x + 2))


# The modular arithmetic operators %/% and %% are not affected by group_by()
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(y = x %% 2) %>%
  group_by(group) %>%
  mutate(z = x %% 2))

# The logarithmic functions log(), log2(), and log10() are not affected by group_by().
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(y = log(x)) %>%
  group_by(group) %>%
  mutate(z = log(x)))

# The offset functions lead() and lag() respect the groupings in group_by(). The functions lag() and lead() will only return values within each group.
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(lag_a = lag(x)) %>%
  group_by(group) %>%
  mutate(
    lag_x = lag(x),
    lead_x = lead(x))
  )

# The cumulative and rolling aggregate functions cumsum(), cumprod(), cummin(), cummax(), and cummean() calculate values within each group.
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(x_cumsum = cumsum(x)) %>%
  group_by(group) %>%
  mutate(x_cumsum_2 = cumsum(x)))

# Logical comparisons, <, <=, >, >=, !=, and == are not affected by group_by().
(tibble(
  x = 1:9,
  y = 9:1,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(x_lte_y = x <= y) %>%
  group_by(group) %>%
  mutate(x_lte_y_2 = x <= y))

# Ranking functions like min_rank() work within each group when used with group_by().
(tibble(
  x = 1:9,
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  mutate(rnk = min_rank(x)) %>%
  group_by(group) %>%
  mutate(rnk2 = min_rank(x)))

#  note that arrange() ignores groups when sorting values.
(tibble(
  x = runif(9),
  group = rep(c("a", "b", "c"), each = 3)
) %>%
  group_by(group) %>%
  arrange(x))

# However, the order of values from arrange() can interact with groups when used with functions that rely on the ordering of elements, such as lead(), lag(), or cumsum().
(tibble(
  group = rep(c("a", "b", "c"), each = 3),
  x = runif(9)
) %>%
  mutate(lag_xno = lag(x)) %>%
  group_by(group) %>%
  arrange(group) %>%
  mutate(lag_x = lag(x)) %>%
  mutate(lead_x = lead(x)))
```

##### Group_by exercises 

* What time of the day should you fly when you want to avoid delays as much as possible? 
```{r}
flights %>%
  group_by(hour) %>%
  summarise(arr_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(arr_delay)
```

* For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.
```{r}
flights %>%
  filter(arr_delay > 0) %>%
  group_by(dest) %>%
  mutate(total_delay = sum(arr_delay),
  arr_delay_prop = arr_delay / total_delay) %>%
  select(dest, total_delay, arr_delay_prop) %>%
  arrange(dest, desc(arr_delay_prop))
```

* Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Use lag() to explore how the delay of a flight is related to the delay of the immediately preceding flight.
```{r}
lagged <- flights %>%
  mutate(prev_delay = lag(dep_delay)) %>%
  filter(!is.na(dep_delay), !is.na(prev_delay))

lagged_delays <- lagged %>% 
  select(prev_delay, dep_delay, origin) %>%
  group_by(dep_delay, prev_delay, origin) %>%
  summarise(dep_delay_mean = mean(dep_delay))
lagged_delays

lagged_delays %>%
  group_by(prev_delay) %>%
  summarise(dep_delay_mean = mean(dep_delay)) %>%
  ggplot(aes(y = dep_delay_mean, x = prev_delay)) +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 1500, by = 120)) +
  labs(y = "Departure Delay", x = "Previous Departure Delay")

#  overall relationship looks similar in all three origin airports.

lagged_delays %>%
  group_by(origin, prev_delay) %>%
  summarise(dep_delay_mean = mean(dep_delay)) %>%
  ggplot(aes(y = dep_delay_mean, x = prev_delay)) +
  geom_point() +
  facet_wrap(~origin, ncol = 2) +
  labs(y = "Departure Delay", x = "Previous Departure Delay")


```

* Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?
```{r}
names(flights)
flights %>%
  filter(!is.na(air_time)) %>%
  group_by(dest, origin) %>%
  summarise(mean_air = mean(air_time)) %>%
  arrange(mean_air)


# To find unusual observations, we need to first put them on the same scale. I will standardize values by subtracting the mean from each and then dividing each by the standard deviation. A standardized variable is often called a z-score. The units of the standardized variable are standard deviations from the mean. This will put the flight times from different routes on the same scale. The larger the magnitude of the standardized variable for an observation, the more unusual the observation is. Flights with negative values of the standardized variable are faster than the mean flight for that route, while those with positive values are slower than the mean flight for that route.

standardized_flights <- flights %>%
  filter(!is.na(air_time)) %>%
  group_by(dest, origin) %>%
  mutate(
    air_time_mean = mean(air_time),
    air_time_sd = sd(air_time),
    n = n()
  ) %>%
  ungroup() %>%
  mutate(air_time_standard = (air_time - air_time_mean) / (air_time_sd + 1)) # 1 is added to avoid deviding by zero 
ggplot(standardized_flights, aes(x = air_time_standard)) +
  geom_density()


unusually fast flights = smallest standardized values 
```{r}
standardized_flights %>%
  arrange(air_time_standard) %>%
  select(
    carrier, flight, origin, dest, month, air_time, air_time_mean, air_time_standard
  ) %>%
  head(10) 

# A potential issue with the way that we standardized the flights is that the mean and standard deviation used to calculate are sensitive to outliers and outliers is what we are looking for. Instead of standardizing variables with the mean and variance, we could use the median as a measure of central tendency and the interquartile range (IQR) as a measure of spread. The median and IQR are more resistant to outliers than the mean and standard deviation. The following method uses the median and inter-quartile range, which are less sensitive to outliers.

standardized_flights2 <- flights %>%
  filter(!is.na(air_time)) %>%
  group_by(dest, origin) %>%
  mutate(
    air_time_median = median(air_time),
    air_time_iqr = IQR(air_time),
    n = n(),
    air_time_standard = (air_time - air_time_median) / air_time_iqr
  )

ggplot(standardized_flights2, aes(x = air_time_standard)) +
  geom_density()

flights %>%
  filter(dep_delay > 0) %>%
  mutate(mph = distance / (air_time/60)) %>%
  ggplot(aes(y = mph, x = dep_delay)) +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 1300, by = 60)) +
  labs(y = "MPH", x = "Dep Delay")

flights %>%
  filter(dep_delay > 0) %>%
  mutate(mph = distance / (air_time/60)) %>%
  select(dep_delay, mph, arr_delay) %>%
  arrange(dep_delay)
```

* Find all destinations that are flown by at least two carriers. Use that information to rank the carriers.

```{r}
flights %>%
  # find all airports with > 1 carrier
  group_by(dest) %>%
  mutate(n_carriers = n_distinct(carrier)) %>%
  filter(n_carriers > 1) %>%
  # rank carriers by numer of destinations
  group_by(carrier) %>%
  dplyr::summarize(n_dest = n_distinct(dest)) %>%
  arrange(desc(n_dest))

```

* For each plane, count the number of flights before the first delay of greater than 1 hour.

```{r}
library(dplyr)
flights %>%
  # sort in increasing order
  select(tailnum, year, month, day, dep_delay) %>%
  filter(!is.na(dep_delay)) %>%
  arrange(tailnum, year, month, day) %>%
  group_by(tailnum) %>%
  # cumulative number of flights delayed over one hour
  mutate(cumulative_hr_delays = cumsum(dep_delay > 60))  %>%
  arrange(cumulative_hr_delays) %>%
  # count the number of flights == 0
  add_count(cumulative_hr_delays < 1, sort = T) 



```

#### lag and lead: 

```{r}
x <- c(1,1,2,2,3,4,5,6,6,7,8,9,9)
lag(x)
lead(x)
x != lag(x)

if (require("nycflights13")) {
carriers <- group_by(flights, carrier)
summarise(carriers, n())
mutate(carriers, n = n())
filter(carriers, n() < 100)
}

carriers <- group_by(flights, carrier) 
```



### Exercises
* using a freq plot instead of a conditional plot
* Both cut_width() and cut_number() split a variable into groups. When using cut_width(), we need to choose the width, and the number of bins will be calculated automatically. When using cut_number(), we need to specify the number of bins, and the widths will be calculated automatically.
* In either case, we want to choose the bin widths and number to be large enough to aggregate observations to remove noise, but not so large as to remove all the signal.
* If categorical colors are used, no more than eight colors should be used in order to keep them distinct. Using cut_number, I will split carats into quantiles (five groups).
```{r}
ggplot(
  data = diamonds,
  mapping = aes(color = cut_number(carat, 5), x = price)
) +
  geom_freqpoly() +
  labs(x = "Price", y = "Count", color = "Carat")
```

Alternatively, I could use cut_width to specify widths at which to cut. I will choose 1-carat widths. Since there are very few diamonds larger than 2-carats, this is not as informative. However, using a width of 0.5 carats creates too many groups, and splitting at non-whole numbers is unappealing.
```{r}
ggplot(
  data = diamonds,
  mapping = aes(color = cut_width(carat, 1, boundary = 0), x = price)
) +
  geom_freqpoly() +
  labs(x = "Price", y = "Count", color = "Carat")
```

Visualize the distribution of carat, partitioned by price.
```{r}
ggplot(diamonds, aes(x = cut_number(price, 10), y = carat)) +
  geom_boxplot() +
  coord_flip() +
  xlab("Price")
```

Plotted with a box plot with 10 equal-width bins of $2,000. The argument boundary = 0 ensures that first bin is $0–$2,000.
```{r}
ggplot(diamonds, aes(x = cut_width(price, 2000, boundary = 0), y = carat)) +
  geom_boxplot(varwidth = TRUE) +
  coord_flip() +
  xlab("Price")
```

Combine two of the techniques you’ve learned to visualize the combined distribution of cut, carat, and price.
```{r}
library(viridis)
ggplot(diamonds, aes(x = carat, y = price)) +
  geom_hex() +
  facet_wrap(~cut, ncol = 1) + # dusplays multiple plots as 'facets' of the cut variable 
  scale_fill_viridis()

ggplot(diamonds, aes(x = cut_number(carat, 5), y = price, colour = cut)) +
  geom_boxplot() +
  labs(x = "Carat", y = "Price")
```

In a normal scatterplot: 
```{r}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = x, y = y)) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```

In this case, there is a strong relationship between x and y. The outliers in this case are not extreme in either x or y. A binned plot would not reveal these outliers, and may lead us to conclude that the largest value of x was an outlier even though it appears to fit the bivariate pattern well.

#### Plotting residuals: 
The residuals give a view of the price of the diamond, once the effect of carat is removed
*add_residuals* adds a single new column to a data frame:
```{r}
library(modelr)
mod <- lm(log(price) ~ log(carat), data = diamonds)
diamonds2 <- diamonds %>% 
  add_residuals(mod) %>%
  mutate(resid = exp(resid)) ## exp because log before 

ggplot(data = diamonds2) +
  geom_point(mapping = aes(x = carat, y = resid))

```
Once the strong relationship between carat and price is taken into account, you can see what you would expect in the relationhip between cut and price - relative to their size, better quality diamonds are more expensive:
```{r}
ggplot(data = diamonds2) + 
  geom_boxplot(mapping = aes(x = cut, y = resid))
```

### Relational Data - Exercises
I add the column flight_id as a surrogate key. I sort the data prior to making the key, even though it is not strictly necessary, so the order of the rows has some meaning.
```{r}
library(dplyr)
nycflights13::flights %>%
  arrange(year, month, day, sched_dep_time, carrier, flight) %>%
  mutate(flight_id = row_number()) %>%
  glimpse()


```
#### Check for primary key 
```{r}
Lahman::Batting %>%
  count(playerID, yearID, stint) %>%
  filter(n > 1) %>%
  nrow()
```
#### OmniGraffle to draw schemas! (See online)

#### package datamodelr to create schemas
```{r}
library(datamodelr)
dm1 <- dm_from_data_frames(list(
  Batting = Lahman::Batting,
  Master = Lahman::Master,
  Salaries = Lahman::Salaries
)) %>%
  dm_set_key("Batting", c("playerID", "yearID", "stint")) %>%
  dm_set_key("Master", "playerID") %>%
  dm_set_key("Salaries", c("yearID", "teamID", "playerID")) %>%
  dm_add_references(
    Batting$playerID == Master$playerID,
    Salaries$playerID == Master$playerID
  )

dm_create_graph(dm1, rankdir = "LR", columnArrows = TRUE) %>%
  dm_render_graph()
```
#### Anti join to check whether there are foreign key relations between tables 
```{r}
nrow(anti_join(Lahman::Pitching, Lahman::Batting,
  by = c("playerID", "yearID", "stint")
))
```

```{r}
sstr <- c("c","ab","B","bba","c",NA,"@","bla","a","Ba","%")
sstr[sstr %in% c(letters, LETTERS)]
setdiff(c(1:6,7:2),      c(3,7,12))

```
### Mutating joins 
```{r}
library(nycflights13)
library(tidyverse)
nycflights13::airports %>%
  semi_join(flights, c("faa" = "dest")) %>%
  ggplot(aes(lon, lat)) +
  borders("state") +
  geom_point() +
  coord_quickmap()
```
You might want to use the size or color of the points to display the average delay for each airport.
```{r}
avg_dest_delays <-
  flights %>%
  group_by(dest) %>%
  # arrival delay NA's are cancelled flights
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
  inner_join(airports, by = c(dest = "faa"))

avg_dest_delays %>%
  ggplot(aes(lon, lat, colour = delay)) +
  borders("state") +
  geom_point() +
  coord_quickmap()
```

<<<<<<< HEAD
### R Programming 
#### The pipe 
When the pipe **doesn't** work:
```{r}
assign("x", 10)
x

"x" %>% assign(100)
x
```
#### Exercises 
In the second variant of rescale01(), infinite values are left unchanged. Rewrite rescale01() so that -Inf is mapped to 0, and Inf is mapped to 1.
```{r}
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  y <- (x - rng[1]) / (rng[2] - rng[1])
  y[y == -Inf] <- 0
  y[y == Inf] <- 1
  y
}

rescale01(c(Inf, -Inf, 0:5, NA))

```
Practice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need? Can you rewrite it to be more expressive or less duplicative?

1. mean(is.na(x))
This code calculates the proportion of NA values in a vector.
```{r}
mean_na <- function(x) {
  m <- mean(is.na(x))
  m
}

mean_na(c(1:5, NA, 3:3, NA))
```
2. x / sum(x, na.rm = TRUE)
This code standardizes a vector so that it sums to one.
```{r}

res <- function(x) {
  g <- x / sum(x, na.rm = T)
  g
}

res(c(1:5, NA, 3:3, NA))

```
3. sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
This code calculates the coefficient of variation (assuming that x can only take non-negative values), which is the standard deviation divided by the mean.
```{r}
var <- function(x) {
  v <- sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
  v
}

var(c(1:5, NA, 3:3, NA))

```
ABS examples
```{r}
# R abs Function example

print("The abosolute Values are:")
# Absolute Values of both Positive and negative zeros
abs(0)
abs(-0)

# Absolute values of Positive values
abs(20)
abs(25.659)

# Absolute Values of Negative values
abs(-10.0897)
abs(-23.659)

# abs on vectors
num <- c(-1.526, 2, -3.5, -4 , -52.7896)
abs(num)

abs(4.441e-16)

```
Write both_na(), a function that takes two vectors of the same length and returns the number of positions that have an NA in both vectors.
```{r}
both_na <- function(x, y) {
  sum(is.na(x) & is.na(y))
}


both_na(
  c(NA, NA, 1, 2, NA, NA, 1),
  c(NA, 1, NA, 2, NA, NA, 1))
  ```
=======

>>>>>>> d594fde4a589c9fa14833a3b665846cac818c0b6

 
``` 

What do the following functions do? Why are they useful even though they are so short?
```{r}
is_directory <- function(x) file.info(x)$isdir
is_readable <- function(x) file.access(x, 4) == 0
```

The function is_directory() checks whether the path in x is a directory. The function is_readable() checks whether the path in x is readable, meaning that the file exists and the user has permission to open it. These functions are useful even though they are short because their names make it much clearer what the code is doing.
 
    Little bunny Foo Foo
    Hopping through the forest
    Scooping up the field mice
    And bopping them on the head

    Down came the Good Fairy, and she said
    "Little bunny Foo Foo
    I don’t want to see you   Scooping up the field mice

    And bopping them on the head.
    I’ll give you three chances,
    And if you don’t stop, I’ll turn you into a GOON!"
    And the next day…

```{r}
# threat <- function(chances) {
#   give_chances(
#     from = Good_Fairy,
#     to = foo_foo,
#     number = chances,
#     condition = "Don't behave",
#     consequence = turn_into_goon
#   )
# }
# 
# lyric <- function() {
#   foo_foo %>%
#     hop(through = forest) %>%
#     scoop(up = field_mouse) %>%
#     bop(on = head)
# 
#   down_came(Good_Fairy)
#   said(
#     Good_Fairy,
#     c(
#       "Little bunny Foo Foo",
#       "I don't want to see you",
#       "Scooping up the field mice",
#       "And bopping them on the head."
#     )
#   )
# }
# 
# lyric()
# threat(3)
# lyric()
# threat(2)
# lyric()
# threat(1)
# lyric()
# turn_into_goon(Good_Fairy, foo_foo)

```
#### Exercises
```{r}
?substr
?nchar
nchar("mayonaise", type = "bytes")

f1 <- function(string, prefix) {
  substr(string, 1, nchar(prefix)) == prefix
}
```
The function f1 tests whether each element of the character vector nchar starts with the string prefix. For example,
```{r}
f1(c("abc", "abcde", "ad"), "ab")

```
A better name for f1 is has_prefix()
```{r}
f2 <- function(x) {
  if (length(x) <= 1) {
    return(NULL)
  }
  x[-length(x)]
}
x = c(7:22, 3, NA, 3:10, -9, 1, -22: -16)
f2 <- function(x) {
  if (length(x) <= 1) return(NULL)
  x[-length(x)]
}

f2(x)

p = 1

f2(p)

x[-length (x)]
x[length(x)]
```
The function f2 drops the last element of the vector x. A better name for f2 is drop_last().
```{r}
f3 <- function(x, y) {
  rep(y, length.out = length(x))
}
?`if`
```
The function f3 repeats y once for each element of x.
length.out = desired length of the sequence 

#### rnorm() versus MASS::mvrnorn()
rnorm() samples from the univariate normal distribution, while MASS::mvrnorm samples from the multivariate normal distribution. The main arguments in rnorm() are n, mean, sd. The main arguments is MASS::mvrnorm are n, mu, Sigma. To be consistent they should have the same names. However, this is difficult. In general, it is better to be consistent with more widely used functions, e.g. rmvnorm() should follow the conventions of rnorm(). However, while mean is correct in the multivariate case, sd does not make sense in the multivariate case. However, both functions are internally consistent. It would not be good practice to have mu and sd as arguments or mean and Sigma as arguments.

#### rnorm and dnorm
If named norm_r() and norm_d(), the naming convention groups functions by their distribution.
If named rnorm(), and dnorm(), the naming convention groups functions by the action they perform.
* r functions always sample from distributions: for example, rnorm(), rbinom(), runif(), and rexp().
* d functions calculate the probability density or mass of a distribution: For example, dnorm(), dbinom(), dunif(), and dexp().
R distributions use this latter naming convention.

### Conditional Execution 
```{r}
has_name <- function(x) {
  nms <- names(x)
  if (is.null(nms)) {
    rep(FALSE, length(x))
  } else {
    !is.na(nms) & nms != ""
  }
}

name_df <- c(1:5)
names(name_df) = c("hh", "ll", NA, NA, "ll")
attributes(name_df)
has_name(name_df)

?rep

```
#### Conditions
* || or && to combine multiple logical expressions 
* never use | or & inside if statements! (these are vectorized operations that apply to multiple values)
* if you do not have a logical vector, you can use any() or all() to collapse it to a single value 
* == is vectorized (more than one output) > check whether input is 1 or use all() or any() or use identical()
  + identical() is very strict! it returns a single TRUE or FALSE and doesn't coerce types 

```{r}
identical(0L, 0)

```
#### Switch function 
* Evaluate section code based on position number
```{r}
switch(2,"red","green","blue")
switch_try <- function(op, x, y) {
  switch(op, 
         plus = x + y,
         minus = x - y,
         times = x * y, 
         divide = x / y, 
         stop("Unknown op!")
       )
}


switch_try(1, 2, 3)

switch("length", "color" = "red", "shape" = "square", "length" = 5)
```
#### Cut function 
*  cut() function divides a numeric vector into different ranges. 
```{r}
x <- rnorm(100)
x

##  Divide the data into ranges -4 ~ 4:
c <- cut(x, breaks = -4:4)
c
```
### Exercises 

1. What is the difference between if and ifelse?

```{r}
 ifelse(3 > 2, 1:3, length(1:3)) 
 if (3 > 2) 1:3 else length(1:3) 
```
* ifelse returns the "shape" of the first argument
* In your ifelse the shape of "3 > 2" is a vector of length one, so it will return a vector length one.
* The keyword if tests a single condition, while ifelse() tests each element.

2. Write a greeting function that says “good morning”, “good afternoon”, or “good evening”, depending on the time of day. (Hint: use a time argument that defaults to lubridate::now(). That will make it easier to test your function.)
```{r}
greet <- function(time = lubridate::now(tzone = "CET")) {
  hr <- lubridate::hour(time)
  if (hr < 12) {
    print("Good morning!")
  } else if (hr < 17) {
    print("Good afternoon!")
  } else {
    print("Good evening!")
  }
}
```
3. Implement a fizzbuzz() function. It takes a single number as input. If the number is divisible by three, it returns “fizz”. If it’s divisible by five it returns “buzz”. If it’s divisible by three and five, it returns “fizzbuzz”. Otherwise, it returns the number. Make sure you first write working code before you create the function.

A more concise way of checking for divisibility is to note that the not operator will return TRUE for 0, and FALSE for all non-zero numbers. Thus, !(x %% y), will check whether y divides x.
```{r}
fizzbuzz <- function(x) {
  # these two lines check that x is a valid input
  stopifnot(length(x) == 1)
  stopifnot(is.numeric(x))
  if (!(x %% 3) && !(x %% 5)) { ## use && in case of single values 
    "fizzbuzz"
  } else if (!(x %% 3)) {
    "fizz"
  } else if (!(x %% 5)) {
    "buzz"
  } else {
    # ensure that the function returns a character vector
    as.character(x)
  }
}
fizzbuzz(150)
```

Instead of only accepting one number as an input, we could write a FizzBuzz function that works on a vector. The case_when() function vectorizes multiple if-else conditions, so is perfect for this task. In fact, fizz-buzz is used in the examples in the documentation of case_when().
```{r}
fizzbuzz_vec <- function(x) {
  case_when(
    !(x %% 3) & !(x %% 5) ~ "fizzbuzz",
    !(x %% 3) ~ "fizz",
    !(x %% 5) ~ "buzz",
    TRUE ~ as.character(x)
  )
}


fizzbuzz_vec(1:55)
```
The following function is an example of a vectorized FizzBuzz function that only uses bracket assignment.
```{r}
fizzbuzz_vec2 <- function(x) {
  y <- as.character(x)
  # put the individual cases first - any elements divisible by both 3 and 5
  # will be overwritten with fizzbuzz later
  y[!(x %% 3)] <- "fizz"
  y[!(x %% 3)] <- "buzz"
  y[!(x %% 3) & !(x %% 5)] <- "fizzbuzz"
  y
}
fizzbuzz_vec2(c(0, 1, 2, 3, 5, 9, 10, 12, 15))

```
4. How could you use cut() to simplify this set of nested if-else statements?
```{r}
temp = 29
if (temp <= 0) {
  "freezing"
} else if (temp <= 10) {
  "cold"
} else if (temp <= 20) {
  "cool"
} else if (temp <= 30) {
  "warm"
} else {
  "hot"
}

temp <- seq(-10, 50, by = 3)
temp
cut(temp, c(-Inf, 0, 10, 20, 30, Inf),
  right = FALSE,
  labels = c("freezing", "cold", "cool", "warm", "hot")
)

?cut

```

#### str: str_dup
```{r}
fruit <- c("apple", "pear", "banana")
str_dup(fruit, 2)
str_dup(fruit, 1:3)
str_c("ba", str_dup("na", 0:5))
# }
```

#### Dot-dot-dot
```{r}
rule <- function(..., pad = "-+") {
  title <- paste0(...)
  width <- getOption("width") - nchar(title) - (0.5* (getOption("width")))
  cat(title, stringr::str_dup(pad, width),  sep = "")
}

rule("Hello, here I am")
```
#### Exercises 
2. It’d be nice if you could supply multiple characters to the pad argument, e.g. rule("Title", pad = "-+"). Why doesn’t this currently work? How could you fix it?
```{r}
rule <- function(..., pad = "-") {
  title <- paste0(...)
  width <- getOption("width") - nchar(title) - 5
  padding <- str_dup(
    pad,
    ceiling(width / str_length(title))
  ) %>%
    str_trunc(width)
  cat(title, padding, sep = "")
}

rule("Important output")
rule("Valuable output", pad = "-+")
rule("Vital output", pad = "-+-")

```
#### str_trunc()
```{r}
x <- "This string is moderately long"
rbind(
  str_trunc(x, 20, "right"),
  str_trunc(x, 20, "left"),
  str_trunc(x, 20, "center"),
  str_trunc(x, 20)
)
```
3. What does the trim argument to mean() do? When might you use it?
* The trim arguments trims a fraction of observations from each end of the vector (meaning the range) before calculating the mean. This is useful for calculating a measure of central tendency that is robust to outliers.

#### cat()
```{r}
args(cat)
# NOT RUN {
iter <- stats::rpois(1, lambda = 10)
iter
## print an informative message
cat("iteration = ", iter <- iter + 1, "\n")

## 'fill' and label lines:
cat(paste(letters, 100* 1:26), fill = TRUE, labels = paste0("{", 1:10, "}:"))
# }

df <- data.frame(replicate(10,sample(0:22,20,rep=TRUE)))
df
show_missings <- function(df) {
  n <- sum(is.na(df))
  cat("Missing values: ", n, "\n", sep = "")
  
  invisible(df)
}

show_missings(df)

```
* Invisible means that the input is still there, it just doesn't get printed out 

#### Create a random data frame
```{r}
sample(seq(0, 6, by=.01), 1)
args(sample)
seq(0, 6, by=.01)
args(seq)

props <- function(ncol, nrow, var.names=NULL){
    if (ncol < 2) stop("ncol must be greater than 1")
    p <- function(n){
        y <- 0
        z <- sapply(seq_len(n-1), function(i) {
                x <- sample(seq(0, 1-y, by=.01), 1)
                y <<- y + x
                return(x)
            }
        )
        w <- c(z , 1-sum(z))
        return(w)
    }
    DF <- data.frame(t(replicate(nrow, p(n = ncol))))
    if (!is.null(var.names)) colnames(DF) <- var.names
    return(DF)
}
##############
# TRY IT OUT #
##############
props(ncol=5, nrow=5)                                      
props(ncol=2, nrow=25)                                     
props(ncol=3, nrow=5, var.names=c("red", "blue", "green"))


```
#### runif() and sample()
```{r}
runif(8)
args(runif)
args(sample)

sample(seq(1, 30, by = runif(1)), 10)


`+` <- function(x, y) {
  if (runif(1) < 1) {
    sum(x,y)
  } else {
    sum(x, y) * 8
  }
}
table(replicate(1000, 1+2))
rm(`+`)


```

## Chapter 16: Vectors
### Exercises
2. Read the source code for dplyr::near() (Hint: to see the source code, drop the ()). How does it work?
```{r}
library(tidyverse)
dplyr::near

```
Instead of checking for exact equality, it checks that two numbers are within a certain tolerance, tol. By default the tolerance is set to the square root of .Machine$double.eps, which is the smallest floating point number that the computer can represent.

### Exercises
2. Carefully read the documentation of is.vector(). What does it actually test for? Why does is.atomic() not agree with the definition of atomic vectors above?

The function is.vector() only checks whether the object has no attributes other than names. Thus a list is a vector:
```{r}
is.vector(list(a = 1, b = 2))
```
But any object that has an attribute (other than names) is not:
```{r}
x <- 1:10
attr(x, "something") <- TRUE
is.vector(x)
```
The idea behind this is that object oriented classes will include attributes, including, but not limited to "class".

The function is.atomic() explicitly checks whether an object is one of the atomic types (“logical”, “integer”, “numeric”, “complex”, “character”, and “raw”) or NULL.

```{r}
is.atomic(1:10)
is.atomic(list(a = 1))
```

The function is.atomic() will consider objects to be atomic even if they have extra attributes.
```{r}
is.atomic(x)
```
3. Compare and contrast setNames() with purrr::set_names().

The biggest difference between set_names() and setNames() is that set_names() allows for using a function or formula to transform the existing names.
```{r}
purrr::set_names(c(a = 1, b = 2, c = 3), ~ toupper(.))
```
4. Create functions that take a vector as input and returns:
1) The last value. Should you use [ or [[?
```{r}
vector <- c(1, 4, 6, 2, 8, 7, 2, 9)
length(vector)
last_v <- vector[[length(vector)]]
last_v
```
2) The elements at even numbered positions.
```{r}
even_indices <- function(x) {
  if (length(x)) {
    x[seq_along(x) %% 2 == 0]
  } else {
    x
  }
}

vector = sample(seq(1,40, by = runif(1)), 10)
vector
seq_along(vector)
seq(vector)

even_indices(numeric())
even_indices(1)
even_indices(1:10)
even_indices(vector)
even_indices(letters)


```

#### lapply()
```{r}
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
x
# compute the list mean for each list element
lapply(x,mean)
# median and quartiles for each list element
lapply(x, quantile, probs = 1:3/4)
sapply(x, quantile)
i39 <- sapply(3:9, seq) # list of vectors
sapply(i39, fivenum)

hist(replicate(100, mean(rexp(10))))


```
3) This function returns a vector with every element except the last.
```{r}
except_last <- function(x) {
  n <- length(x)
  if(n) {
    x[seq(1, (length(x) -1))]
  } else {
    x
  }
}
except_last(vector)

except_last(1) ## this does not work!]
# So new try:

except_last2 <- function(x) {
  n <- length(x)
  if (n) {
    x[-n]
  } else {
    x
  }
}

except_last2(1)

# Yey!

```
4) Only even numbers 
```{r}
even_numbers2 <- function(x) {
  x[!is.infinite(x) & !is.nan(x) & (x %% 2 == 0)]
}
even_numbers2(c(0:4, NA, NaN, Inf, -Inf))
```
#### Exercises for loop
1. Write for loops to: 
a. Compute the mean of every column in mtcars 
```{r}
output <- vector("double", ncol(mtcars))
names(output) <- names(mtcars)
for (coli in names(mtcars)) {
  output[coli] <- mean(mtcars[[coli]])
}

```
b. determine the type of each column in nyc flights13::flights 
* I used a list, not a character vector, since the class of an object can have multiple values. For example, the class of the time_hour column is POSIXct, POSIXt.
```{r}
library(nycflights13)
output <- vector("list", ncol(nycflights13::flights))
names(output) <- names(nycflights13::flights)
for (i in names(nycflights13::flights)) {
  output[[i]] <- class(nycflights13::flights[[i]])
}
```
c. Compute the number of unique values in each column of iris 
```{r}
data("iris")
iris_uniq <- vector("double", ncol(iris))
names(iris_uniq) <- names(iris)
for (i in names(iris)) {
  iris_uniq[i] <- length(unique(iris[[i]]))
}
```

d. Gnenerate 10 random normals for each of mu = -10, 0, 10 and 100 
```{r}
n <- 10
# values of the mean
mu <- c(-10, 0, 10, 100)
normals <- vector("list", length(mu))
for (i in seq_along(normals)) {
  normals[[i]] <- rnorm(n, mean = mu[i])
}
normals
```

2. Eliminate the for loop in each of the following examples by taking advantage of an existing function that works with vectors:
```{r}
out <- ""
for (x in letters) {
  out <- str_c(out, x)
}
out

new_lett <- vector()
for (x in letters) {
  new_lett[x] <- paste(x, "hallo")
}

(new_lett)
```
Since str_c() already works with vectors, use str_c() with the collapse argument to return a single string.
```{r}
str_c(letters, collapse = "")
```


```{r}
x <- sample(100)
sd. <- 0
for (i in seq_along(x)) {
  sd. <- sd. + (x[i] - mean(x))^2
}
sd. <- sqrt(sd. / (length(x) - 1))
sd.

```
We could simply use the sd function.
```{r}
sd(x)
```

```{r}
x <- runif(100)
out <- vector("numeric", length(x))
out[1] <- x[1]
for (i in 2:length(x)) {
  out[i] <- out[i - 1] + x[i]
}
out
x
```
The code above is calculating a cumulative sum. Use the function cumsum()
```{r}
all.equal(cumsum(x), out)
?all.equal
```
Combine your function writing and for loop skills:
1. Write a for loop that prints() the lyrics to the children’s song “Alice the camel”.

The lyrics for Alice the Camel are:

    Alice the camel has five humps.
    Alice the camel has five humps.
    Alice the camel has five humps.
    So go, Alice, go.
    
This verse is repeated, each time with one fewer hump, until there are no humps. The last verse, with no humps, is:   

    Alice the camel has no humps.
    Alice the camel has no humps.
    Alice the camel has no humps.
    Now Alice is a horse.

We’ll iterate from five to no humps, and print out a different last line if there are no humps.
```{r}
humps <- c("five", "four", "three", "two", "one", "no")
alice <- function() {
  for (i in humps) {
    cat(str_c("Alice the camel has ", rep(i, 3), " humps.",
              collapse = "\n"
              ), "\n")
    if (i == "no") {
      cat("Now Alice is a horse. \n")
    } else {
      cat("So go, Alice, go. \n")
    }
   cat("\n")
  } 
}

alice()
```
Ten green bottles hanging on the wall,
Ten green bottles hanging on the wall,
And if one green bottle should accidentally fall,
There'll be nine green bottles hanging on the wall.

Nine green bottles hanging on the wall,
Nine green bottles hanging on the wall,
And if one green bottle should accidentally fall,
There'll be eight green bottles hanging on the wall.
...

One green bottle hanging on the wall,
One green bottle hanging on the wall,
And if one green bottle should accidentally fall,
There'll be no green bottles hanging on the wall. 

#### str_c()
```{r}
str_c("Letter: ", letters)
str_c("Letter", letters, sep = ": ")
str_c(letters, " is for", "...")
str_c(letters[-26], " comes before ", letters[-1])

str_c(letters, collapse = "")
str_c(letters, collapse = ", ")
```


```{r}
?str_c
?rep
number <- c("Ten", "Nine", "Eight", "Seven", "Six", "Five", "Four", "Three", "Two")
and_if <- ("And if one green bottle should accidentally fall,")

bottles <- function() {
  for (num in number) {
    cat(str_c(rep(num, 2), " green bottles hanging on the wall", collapse = "\n"), "\n", and_if, "\n", "There'll be", number[2], "green bottles hanging on the wall", "\n", "\n")
    if (num == "Two") {
   cat(str_c(rep("One green bottle hanging on the wall", 2), collapse = "\n"), "\n", and_if, "\n", "There'll be no green bottles hanging on the wall", "\n", "\n")     
    }
  }
}

bottles()

library(stringr)
bottles <- function() {
  for (i in seq_along(number)) {
    cat(str_c(rep(number[i], 2), " green bottles hanging on the wall", collapse = "\n"), "\n", and_if, "\n", "There'll be", number[i+1], "green bottles hanging on the wall", "\n", "\n")
    if (i == length(number)) {
   cat(str_c(rep("One green bottle hanging on the wall", 2), collapse = "\n"), "\n", and_if, "\n", "There'll be no green bottles hanging on the wall", "\n", "\n")     
    }
  }
}

bottles()
```

```{r}
seq(10,0)
```
3. Convert the lyrics of Ninety-Nine Bottles of Beer on the Wall
```{r}
## My solution: 
bottles <- function(n) {
  if (n > 0) {
    for (i in seq_along(n)) {
      cat(str_c(as.character(n[i]), " bottles of beer on the wall,", as.character(n[i]), " bottles of beer.", "\n","Take one down, pass it around, ", as.character(n[i]-1), " bottles of beer on the wall", collapse = "\n"))
    }
  } else if (n == 0) {
    cat(str_c("No more bottles of beer on the wall, no more bottles of beer.",
              "\n", "We’ve taken them down and passed them around; now we’re drunk and","\n", "passed out!"))
  }
}

bottles(0)

## suggested solution:
bottles <- function(n) {
  if (n > 1) {
    str_c(n, " bottles")
  } else if (n == 1) {
    "1 bottle"
  } else {
    "no more bottles"
  }
}

beer_bottles <- function(total_bottles) {
  # print each lyric
  for (current_bottles in seq(total_bottles, 0)) {
    # first line
    cat(str_to_sentence(str_c(bottles(current_bottles), " of beer on the wall, ", bottles(current_bottles), " of beer.\n")))
    # second line
    if (current_bottles > 0) {
      cat(str_c(
        "Take one down and pass it around, ", bottles(current_bottles - 1),
        " of beer on the wall.\n"
      ))
    } else {
      cat(str_c("Go to the store and buy some more, ", bottles(total_bottles), " of beer on the wall.\n"))
    }
    cat("\n")
  }
}
beer_bottles(3)

```
4. It’s common to see for loops that don’t preallocate the output and instead increase the length of a vector at each step:

```{r}
x = c(10, 8, 2, 7, 20, 34)
output <- vector("integer", 0)
for (i in seq_along(x)) {
  output <- c(output, lengths(x[[i]]))
}
output
```
How does this affect performance? Design and execute an experiment.

In order to compare these two approaches, I’ll define two functions: add_to_vector will append to a vector, like the example in the question, and add_to_vector_2 which pre-allocates a vector.

```{r}
add_to_vector <- function(n) {
  output <- vector("integer", 0)
  for (i in seq_len(n)) {
    output <- c(output, i)
  }
  output
}

add_to_vector_2 <- function(n) {
  output <- vector("integer", n)
  for (i in seq_len(n)) {
    output[[i]] <- i
  }
  output
}
```
I’ll use the package microbenchmark to run these functions several times and compare the time it takes. The package microbenchmark contains utilities for benchmarking R expressions. In particular, the microbenchmark() function will run an R expression a number of times and time it.
```{r}
library(microbenchmark)

timings <- microbenchmark(add_to_vector(10000), add_to_vector_2(10000), times = 10)
timings
```
#### Looping patterns
1. Loop over elements
```{r}
x <- (runif(10))
x
names(x) <- letters[1:10]
for (n in x) {
  cat(str_c("Hello, this is my random number: ", n, "!\n"))
}
```
2. Loop over numeric indices 
```{r}
library(stringr)
x <- c(runif(10))
y <- c(1, "v", TRUE, 2, "apple", FALSE)
names(x) <- letters[1:10]
one <- "1st"
two <- "2nd"
three <- "3rd"
Hello <- "Hello, this is my "
And <- ". And this is my "

for (i in seq_along(x)){
  if(i ==1){
    cat(str_c(Hello, one, " number: ", x[[i]], "!\n"))  
  } else if (i == 2) {
      cat(str_c(Hello, two, " number: ", x[[i]], And, one, "number: ", x[[i-1]])) 
  } else if (i == 3){
    cat(str_c("\nHello, this is my 3rd number: ", x[[i]], "! And this is my 2nd number: ", x[[i-1]])) 
  } else if (i > 3) {
  cat(str_c("\nHello, this is my ", i, "th ","number: ", x[[i]], "! And this is my ", i-1, "th number: !", x[[i-1]]))
  }
}

for (i in seq_along(y)){
  if(i ==1){
    cat(str_c(Hello, one, " number: ", y[[i]], "!\n"))  
  } else if (i == 2) {
      cat(str_c(Hello, two, " number: ", y[[i]], And, one, " number: ", y[[i-1]])) 
  } else if (i == 3){
    cat(str_c("\nHello, this is my 3rd number: ", y[[i]], "! And this is my 2nd number: ", y[[i-1]])) 
  } else if (i > 3) {
  cat(str_c("\nHello, this is my ", i, "th ","number: ", y[[i]], "! And this is my ", i-1, "th number:", y[[i-1]]))
  }
}
```
3. Loop over names
```{r}
x <- c(runif(10))
names(x) <- letters[1:10]

for (name in names(x)) {
  cat(str_c("Hello, this is the name: ", name, "\n"))
}

```
Iteration over numeric indices allows to extract both the name and the value:
```{r}
x <- c(runif(10))
names(x) <- letters[1:10]
for (i in seq_along(x)) {
  n <- names(x)[[i]]
  v <- x[[i]]
  cat(str_c("This is the name: ", n, "\tand this is the value: ", v, "\n"))
}
```
#### collape argument of str_c
```{r}
str_c("Letter: ", letters)
str_c("Letter", letters, sep = ": ")
str_c(letters, " is for", "...")
str_c(letters[-26], " comes before ", letters[-1])

str_c(letters, collapse = "")
str_c(letters, collapse = ", ")
```
#### Unknown output length
```{r}
means <- c(0,1)
output <- double()
for (i in seq_along(means)) {
  n <- sample(100,1)
  output <- c(output, rnorm(n, means[[i]]))
}

str(output)

## Better: 
# Save results in a list and combine into single vector after the loop is done
out <- vector("list", length(means))
for (i in seq_along(means)) {
  n <- sample(100, 1)
  out[[i]] <- rnorm(n, means[[i]])
}

str(out)
str(unlist(out))
out

out[1]
out[2]

n <- sample(100,1)
r <- rnorm(10, mean = 6, sd = 2)
r
mean(r)
sd(r)

?rnorm
```
#### Unknown sequence length
```{r}
flip <- function() sample(c("H", "T"), 1)
flip()

flips <- 0
heads <- 0
  
while(flips < 10) {
  result <- flip()
  flips <- flips + 1
  if (result == "H") {
    cat("Yeah, heads!\n")
    heads <- heads + 1
  }
}

print(heads)

```
## Exercises 
#### Read in multiple files in a for loop
```{r}
files <- dir("data/", pattern = "\\.csv$", full.names = TRUE)
```
Since, the number of files is known, pre-allocate a list with a length equal to the number of files.
```{r}
df_list <- vector("list", length(files))
```
Then, read each file into a data frame, and assign it to an element in that list. The result is a list of data frames.
```{r}
for (i in seq_along(files)) {
  df_list[[i]] <- read_csv(files[[i]])
}
```
Finally, use use bind_rows() to combine the list of data frames into a single data frame.
```{r}
df <- bind_rows(df_list)
```
Alternatively, I could have pre-allocated a list with the names of the files.
```{r}
df2_list <- vector("list", length(files))
names(df2_list) <- files
for (fname in files) {
  df2_list[[fname]] <- read_csv(fname)
}
```
What happens if you use for (nm in names(x)) and x has no names? What if only some of the elements are named? What if the names are not unique?

If the vector contains duplicate names, then x[[nm]] returns the first element with that name.
```{r}
x <- c(a = 11, a = 12, c = 13)
names(x)
```
Write a function that prints the mean of each numeric column in a data frame, along with its name. For example, show_mean(iris) would print:
```{r}
show_mean(iris)
show_mean <- function(df, digits = 2) {
  # Get max length of all variable names in the dataset
  maxstr <- max(str_length(names(df)))
  for (nm in names(df)) {
    if (is.numeric(df[[nm]])) {
      cat(
        str_c(str_pad(str_c(nm, ":"), maxstr + 5L, side = "right"),
          format(mean(df[[nm]]), digits = digits, nsmall = digits),
          sep = " "
        ),
        "\n"
      )
    }
  }
}

?str_pad
?format
```
#### str_pad
```{r}
rbind(
  str_pad("hadley", 30, "left"),
  str_pad("hadley", 20, "right"),
  str_pad("hadley", 50, "both")
)

# All arguments are vectorised except side
str_pad(c("a", "abc", "abcdef"), 10)
str_pad("a", c(5, 10, 20))
str_pad("a", 10, pad = c("-", "_", " "))

# Longer strings are returned unchanged
str_pad("hadley", 3)
```
#### format()
```{r}
## a list
z <- list(a = letters[1:3], b = (-pi+0i)^((-2:2)/2), c = c(1,10,100,1000),
          d = c("a", "longer", "character", "string"),
          q = quote( a + b ), e = expression(1+x))
## can you find the "2" small differences?
(f1 <- format(z, digits = 2))
(f2 <- format(z, digits = 2, justify = "left", trim = FALSE))
f1 == f2 ## 2 FALSE, 4 TRUE

## A "minimal" format() for S4 objects without their own format() method:
cc <- methods::getClassDef("standardGeneric")
format(cc) ## "<S4 class ......>"

```
What does this code do? How does it work?
```{r}
trans <- list(
  disp = function(x) x * 0.0163871,
  am = function(x) {
    factor(x, labels = c("auto", "manual"))
  }
)

for (var in names(trans)) {
  mtcars[[var]] <- trans[[var]](mtcars[[var]])
}

trans
```
This code mutates the disp and am columns:

* disp is multiplied by 0.0163871
* am is replaced by a factor variable.

The code works by looping over a named list of functions. It calls the named function in the list on the column of mtcars with the same name, and replaces the values of that column.

This is a function.

```{r}
trans
trans[["disp"]]

# This applies the function to the column of mtcars with the same name:
trans[["disp"]](mtcars[["disp"]])


```
#### Exercises
Read the documentation for apply(). In the 2nd case, what two for-loops does it generalize.

For an object with two-dimensions, such as a matrix or data frame, apply() replaces looping over the rows or columns of a matrix or data-frame. The apply() function is used like apply(X, MARGIN, FUN, ...), where X is a matrix or array, FUN is a function to apply, and ... are additional arguments passed to FUN.

When MARGIN = 1, then the function is applied to each row. For example, the following example calculates the row means of a matrix.
```{r}
X <- matrix(rnorm(15), nrow = 5)
X
apply(X, 1, mean)
```
That is equivalent to this for-loop.
```{r}
X_row_means <- vector("numeric", length = nrow(X))
for (i in seq_len(nrow(X))) {
  X_row_means[[i]] <- mean(X[i, ])
}
X_row_means
```
When MARGIN = 2, apply() is equivalent to a for-loop looping over columns.
```{r}
apply(X, 2, mean)
X_col_means <- vector("numeric", length = ncol(X))
for (i in seq_len(ncol(X))) {
  X_col_means[[i]] <- mean(X[, i])
}
X_col_means
```
Adapt col_summary() so that it only applies to numeric columns. You might want to start with an is_numeric() function that returns a logical vector that has a TRUE corresponding to each numeric column.
```{r}
# The original function: 
col_summary <- function(df, fun) {
  out <- vector("double", length(df))
  for (i in seq_along(df)) {
    out[i] <- fun(df[[i]])
  }
  out
}

# The new function: 
col_summary2 <- function(df, fun) {
  # create an empty vector which will store whether each
  # column is numeric
  numeric_cols <- vector("logical", length(df))
  # test whether each column is numeric
  for (i in seq_along(df)) {
    numeric_cols[[i]] <- is.numeric(df[[i]])
  }
  # find the indexes of the numeric columns
  idxs <- which(numeric_cols)
  # find the number of numeric columns
  n <- sum(numeric_cols)
  # create a vector to hold the results
  out <- vector("double", n)
  # apply the function only to numeric vectors
  for (i in seq_along(idxs)) {
    out[[i]] <- fun(df[[idxs[[i]]]])
  }
  # name the vector
  names(out) <- names(df)[idxs]
  out
}

df <- tibble(
  X1 = c(1, 2, 3),
  X2 = c("A", "B", "C"),
  X3 = c(0, -1, 5),
  X4 = c(TRUE, FALSE, TRUE)
)

col_summary2(df, mean)
?which

```

#### which()
```{r}
LETTERS
which(LETTERS == "R")
which(ll <- c(TRUE, FALSE, TRUE, NA, FALSE, FALSE, TRUE)) #> 1 3 7
names(ll) <- letters[seq(ll)]
which(ll)
which((1:12)%%2 == 0) # which are even?
which(1:10 > 3, arr.ind = TRUE)

( m <- matrix(1:12, 3, 4) )
div.3 <- m %% 3 == 0
which(div.3)
which(div.3, arr.ind = TRUE)
rownames(m) <- paste("Case", 1:3, sep = "_")
rownames(m)
which(m %% 5 == 0, arr.ind = TRUE)

dim(m) <- c(2, 2, 3); m
which(div.3, arr.ind = FALSE)
which(div.3, arr.ind = TRUE)

vm <- c(m)
dim(vm) <- length(vm) #-- funny thing with  length(dim(...)) == 1
which(div.3, arr.ind = TRUE)
```
#### Exercises map()
1. Write code that uses one of the map functions to:

a. Compute the mean of every column in mtcars.
b. Determine the type of each column in nycflights13::flights.
c. Compute the number of unique values in each column of iris.
d. Generate 10 random normals for each of μ=−10, 0, 10, and 100.

a. 
```{r}
mtcars %>% 
  map_dbl(mean)

map_dbl(mtcars, mean)
```

b.
```{r}
map(nycflights13::flights, typeof)
```

c. 
There is no function that directly calculates the number of unique values in a vector. For a single column, the number of unique values of a vector can be calculated like so:
```{r}
length(unique(iris$Species))
```
To apply this to all columns, we can provide the map an anonymous function. We can write anonymous function using the standard R syntax.
```{r}
map_int(iris, function(x) length(unique(x)))
```
We could also use the compact, one-sided formula shortcut that purrr provides.
```{r}
map_int(iris, ~ length(unique(.)))
```

d. Generate 10 random normals for each of mu = -10, 0, 10, 100
```{r}
map(c(-10, 0, 10, 100), ~ rnorm(n = 10, mean = .))
```
 
2. How can you create a single vector that for each column in a data frame indicates whether or not it's a factor? 
```{r}
is.factor(diamonds$color)
```
To check if each of the columns is a factor use map_*()! the result of is.factor() is logical -> map_lgl() to apply is.factor() to the columns of the data frame
```{r}
map_lgl(diamonds, is.factor)
```
3. What happens when you use the map functions on vectors that aren't lists? What does map(1:5, runif) do? Why?
```{r}
vector <- as_vector(1:9)
map(vector, sum)
map(1:5, runif)
map(c(1.5, 6.3, 7.4), ~ rnorm(3, mean = .))


```
4. What does map(-2:2, rnorm, n = 5) do? Why? What does map_dbl(-2:2, rnorm, n = 5) do? Why?
```{r}
map(-2:2, rnorm, n = 5)
map_dbl(-2:2, rnorm, n = 5) 
map_dbl(-2:2, rnorm, n = 1) 
```
5. Rewrite the 




